{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915021d1",
   "metadata": {},
   "source": [
    "# [ë¬¸ì œ]\n",
    "- law_2.docx íŒŒì¼ì„ ì½ê³ , Chroma ì €ì¥\n",
    "- LLMì— ì§ˆë¬¸ -> ë‹µë³€\n",
    "- 'ì „ì œì‚¬ê¸°í”¼í•´'ì— ê´€í•œ ë²•ë¥  ì§ˆë¬¸ë§Œ ë°›ê¸°\n",
    "- ì´ ì™¸ì˜ ì§ˆë¬¸ì„ í•˜ë©´ 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5c2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ëª¨ë“ˆ\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc944ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ì½ê³  Chromaì— ì €ì¥\n",
    "loader = Docx2txtLoader('law_2.docx')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f66d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ë¶„ë¦¬\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367e7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²¡í„° DBì— ì €ì¥\n",
    "vector_db = Chroma.from_documents(\n",
    "    docs,\n",
    "    OpenAIEmbeddings(),\n",
    "    persist_directory='./chroma_db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6975f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG QA Chain ìƒì„±\n",
    "retriever = vector_db.as_retriever()\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(model='gpt-4o'),\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4969fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ë‹µë³€: ì „ì„¸ì‚¬ê¸°í”¼í•´ëŠ” ì£¼íƒì„ëŒ€ì°¨ ê³„ì•½ì—ì„œ ë°œìƒí•˜ëŠ” ì‚¬ê¸°ë¡œ, ì£¼ë¡œ ì„ì°¨ì¸ì´ ì „ì„¸ê¸ˆì„ ìƒê²Œ ë˜ëŠ” ìƒí™©ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ì§‘ì£¼ì¸ì´ ì„ì°¨ì¸ì—ê²Œ ì „ì„¸ê¸ˆì„ ë°›ì•„ ë†“ê³ ë„ ì£¼íƒë‹´ë³´ëŒ€ì¶œì„ ê°šì§€ ì•Šê±°ë‚˜ ì£¼íƒì„ ì„ì˜ë¡œ ë§¤ê°í•˜ì—¬ ì„ì°¨ì¸ì—ê²Œ ìƒí™˜ë˜ì§€ ì•ŠëŠ” ê²½ìš° ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì‚¬ê¸°ëŠ” ì„ì°¨ì¸ì˜ ê²½ì œì  ì†ì‹¤ì„ ì´ˆë˜í•˜ë©°, ì „ì„¸ì‚¬ê¸°í”¼í•´ìë¥¼ ë³´í˜¸íˆê¸° ìœ„í•œ íŠ¹ë³„ë²• ë° ì‹œí–‰ë ¹ì´ ë§ˆë ¨ë˜ì–´ ìˆê¸°ë„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”— ì†ŒìŠ¤ 1:\n",
      " ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì§€ì› ë° ì£¼ê±°ì•ˆì •ì— ê´€í•œ íŠ¹ë³„ë²• ì‹œí–‰ë ¹ ( ì•½ì¹­: ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²• ì‹œí–‰ë ¹ )\n",
      "\n",
      "ğŸ”— ì†ŒìŠ¤ 2:\n",
      " ì „ì„¸ì‚¬ê¸°í”¼í•´ì ì§€ì› ë° ì£¼ê±°ì•ˆì •ì— ê´€í•œ íŠ¹ë³„ë²• ì‹œí–‰ë ¹ ( ì•½ì¹­: ì „ì„¸ì‚¬ê¸°í”¼í•´ìë²• ì‹œí–‰ë ¹ )\n",
      "\n",
      "ğŸ”— ì†ŒìŠ¤ 3:\n",
      " 1. ì „ì„¸ì‚¬ê¸°í”¼í•´ì£¼íƒ ë§¤ì…ê¸ˆì•¡\n",
      "\n",
      "ğŸ”— ì†ŒìŠ¤ 4:\n",
      " 1. ì „ì„¸ì‚¬ê¸°í”¼í•´ì£¼íƒ ë§¤ì…ê¸ˆì•¡\n",
      "â—ï¸ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "â—ï¸ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "â—ï¸ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ë°›ê¸°\n",
    "while True:\n",
    "    query = input(\"ì „ì„¸ì‚¬ê¸°í”¼í•´ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'q' ì…ë ¥): \")\n",
    "    \n",
    "    if query.lower() == 'q':\n",
    "        print(\"ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        break\n",
    "\n",
    "    if 'ì „ì„¸ì‚¬ê¸°í”¼í•´' in query:\n",
    "        # LLMì— ì§ˆë¬¸ê³¼ í•¨ê»˜ ë¹ˆ chat_history ì „ë‹¬\n",
    "        result = qa_chain.invoke({\n",
    "            'question': query,\n",
    "            'chat_history': []\n",
    "        })\n",
    "        \n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print('\\nğŸ“Œ ë‹µë³€:', result.get('answer', 'ë‹µë³€ ì—†ìŒ'))\n",
    "\n",
    "        # ì†ŒìŠ¤ ë¬¸ì„œë„ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ì²˜ëŸ¼ ì¶œë ¥ ê°€ëŠ¥\n",
    "        for idx, doc in enumerate(result.get('source_documents', [])):\n",
    "            print(f\"\\nğŸ”— ì†ŒìŠ¤ {idx+1}:\\n\", doc.page_content)\n",
    "    else:\n",
    "        print(\"â—ï¸ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
