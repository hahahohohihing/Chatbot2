{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915021d1",
   "metadata": {},
   "source": [
    "# [문제]\n",
    "- law_2.docx 파일을 읽고, Chroma 저장\n",
    "- LLM에 질문 -> 답변\n",
    "- '전제사기피해'에 관한 법률 질문만 받기\n",
    "- 이 외의 질문을 하면 '답변을 할 수 없습니다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "## 환경변수 읽어오기\n",
    "load_dotenv()\n",
    "## 문서 내용 읽고 분할\n",
    "loader = Docx2txtLoader('law_2.docx')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "## 임베딩 - > 벡터 데이터베이스에 저장, 모델 지정\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "\n",
    "# ## 벡터 데이터베이스에 저장 [메모리]\n",
    "# database = Chroma.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "# )\n",
    "## 로컬에 저장된 임베딩 갖고 오기\n",
    "database = Chroma(\n",
    "    collection_name='chroma-law',\n",
    "    persist_directory='./chroma',\n",
    "    embedding_function=embedding,\n",
    ")\n",
    "\n",
    "database\n",
    "## 질문이 있으면, 벡터 데이터베이스에서 유사도 검색\n",
    "query = '전세사기피해자로 인정받기 위한 조건은?'\n",
    "\n",
    "## 유사도 검색으로 가져온 문서 LLM 전달\n",
    "prompt = '''\n",
    "[indentity]\n",
    "- 너는 전세사기피해 법률 전문가이다\n",
    "- [context]를 참고하여 사용자의 질문에 답변해 주세요\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question: {query}\n",
    "'''\n",
    "\n",
    "## LLM 모델 생성\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3037c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='전세사기피해는 주로 임대차 계약과 관련된 사기 형태로, 임차인이 보증금을 떼이거나 손해를 보는 경우를 말합니다. 전세 사기는 다양한 방법으로 이루어질 수 있습니다. 예를 들어, 임대인이 실제로는 소유하지 않은 주택을 임대하는 경우, 주택에 설정된 담보나 채무를 숨기고 임차인을 속이는 경우, 혹은 전세 계약이 끝나기 전에 보증금을 돌려주지 않는 경우 등이 있습니다. 이러한 사기로 인해 임차인은 큰 금전적 손해를 입을 수 있으며, 경우에 따라 주거지를 잃는 심각한 상황에 처할 수 있습니다. 전세사기를 예방하기 위해서는 계약 전에 등기부등본을 확인하고, 반드시 공증 절차를 거치는 등의 주의가 필요합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 190, 'prompt_tokens': 57, 'total_tokens': 247, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9bddfca6e2', 'id': 'chatcmpl-BeMlEjOnzLL0bXZb82qhRfgEMT3mc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0684c200-23b7-47f4-afab-eb2f7a44b863-0' usage_metadata={'input_tokens': 57, 'output_tokens': 190, 'total_tokens': 247, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "content='전세사기피해자 지원 및 주거안정에 관한 특별법 시행령은 전세 사기 피해자들을 보호하고 지원하기 위해 제정된 법률의 하위 규정입니다. 이 시행령은 법률에서 규정한 사항을 구체적으로 실행하기 위한 세부적인 지침과 절차를 제공합니다. 주로 전세 사기 피해자의 주거 안정을 위해 필요한 지원 방안, 지원 대상과 지원 절차, 피해 복구를 위한 정부의 역할 등을 다루고 있습니다.\\n\\n이 시행령은 피해자들이 신속하게 지원을 받을 수 있도록 돕고, 전세 사기로 인해 발생할 수 있는 주거 불안정 문제를 해결하는 데 목적이 있습니다. 구체적으로는 피해 사실의 인정 기준, 지원금 및 대출 지원 방법, 피해자에 대한 법률 상담 및 심리 지원, 주거지 제공 등의 내용을 포함할 수 있습니다. 이러한 규정들은 피해자들이 안정적으로 생활을 이어나가고, 전세 사기 문제가 사회적으로 최소화될 수 있도록 기여합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 227, 'prompt_tokens': 69, 'total_tokens': 296, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BeMn7XBn06agsHVZ43a3kUrNFQnc2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0203ebca-d484-410d-9bc2-0402a94c99f5-0' usage_metadata={'input_tokens': 69, 'output_tokens': 227, 'total_tokens': 296, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n",
      "답변할 수 없습니다\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## LLM 모델에 질문과 검색된 문서를 보냄\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m전세사기피해에 대해 질문하세요 [종료하려면 S]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m종료합니다\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/project/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/project/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "## LLM 모델에 질문과 검색된 문서를 보냄\n",
    "while True:\n",
    "    query = input('전세사기피해에 대해 질문하세요 [종료하려면 S]')\n",
    "\n",
    "    if query.upper()=='s':\n",
    "        print('종료합니다')\n",
    "        break\n",
    "\n",
    "    if '전세사기피해' not in query:\n",
    "        print('답변할 수 없습니다')\n",
    "        continue\n",
    "\n",
    "    ## 벡터 데이터베이스에서 유사도 검색\n",
    "    retrieved_docs = database.similarity_search(query=query, k=3)\n",
    "    \n",
    "    formatted_prompt =  prompt.format(\n",
    "    retrieved_docs=retrieved_docs,\n",
    "    query=query\n",
    "    )\n",
    "\n",
    "    \n",
    "    ## 프롬프트 변수에 값 설정\n",
    "    response = llm.invoke([\n",
    "        HumanMessage(content=formatted_prompt)\n",
    "    ])\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
